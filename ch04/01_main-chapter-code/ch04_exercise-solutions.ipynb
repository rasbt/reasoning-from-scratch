{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83efb6df-7d99-4fee-99f3-f2f668292110",
   "metadata": {},
   "source": [
    "<table style=\"width:100%\">\n",
    "<tr>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<font size=\"2\">\n",
    "Supplementary code for the <a href=\"https://mng.bz/lZ5B\">Build a Reasoning Model (From Scratch)</a> book by <a href=\"https://sebastianraschka.com\">Sebastian Raschka</a><br>\n",
    "<br>Code repository: <a href=\"https://github.com/rasbt/reasoning-from-scratch\">https://github.com/rasbt/reasoning-from-scratch</a>\n",
    "</font>\n",
    "</td>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<a href=\"https://mng.bz/lZ5B\"><img src=\"https://sebastianraschka.com/images/reasoning-from-scratch-images/cover-small.webp\" width=\"100px\"></a>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2ac59f-0dc1-4c3e-bb8c-2ea79e0f6657",
   "metadata": {},
   "source": [
    "# Chapter 4: Exercise Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4735f8bb-dd7f-4a4f-8761-269f26b38349",
   "metadata": {},
   "source": [
    "Packages that are being used in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00e26411-6a34-4c89-bc24-2e36dd14c8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reasoning_from_scratch version: 0.1.9\n",
      "torch version: 2.9.0\n",
      "tokenizers version: 0.21.4\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "used_libraries = [\n",
    "    \"reasoning_from_scratch\",\n",
    "    \"torch\",\n",
    "    \"tokenizers\"  # Used by reasoning_from_scratch\n",
    "]\n",
    "\n",
    "for lib in used_libraries:\n",
    "    print(f\"{lib} version: {version(lib)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d101721-6848-4871-826a-eaf194ddb26a",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "## Exercise 4.1: Use chain-of-thought prompting on MATH-500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9257c6-384b-46a0-9767-c2f3db7dbcf0",
   "metadata": {},
   "source": [
    "- The modification just requires adding a prompt suffix, for example \"\\n\\nExplain step by step.\" after applying the prompt template\n",
    "- The modified MATH-500 evaluation function from chapter 3 is shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea1e9276-21f4-49f0-8897-4a475e5f1858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "from reasoning_from_scratch.ch03 import (\n",
    "    eta_progress_message,\n",
    "    extract_final_candidate,\n",
    "    render_prompt,\n",
    "    grade_answer,\n",
    "    generate_text_stream_concat,\n",
    ")\n",
    "\n",
    "\n",
    "def evaluate_math500_stream(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    device,\n",
    "    math_data,\n",
    "    out_path=None,\n",
    "    max_new_tokens=512,\n",
    "    verbose=False,\n",
    "    prompt_suffix=\"\"  # NEW\n",
    "):\n",
    "\n",
    "    if out_path is None:\n",
    "        dev_name = str(device).replace(\":\", \"-\")\n",
    "        out_path = Path(f\"math500-{dev_name}.jsonl\")\n",
    "\n",
    "    num_examples = len(math_data)\n",
    "    num_correct = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for i, row in enumerate(math_data, start=1):\n",
    "            prompt = render_prompt(row[\"problem\"])\n",
    "            prompt += prompt_suffix  # NEW\n",
    "            gen_text = generate_text_stream_concat(\n",
    "                model, tokenizer, prompt, device,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                verbose=verbose,\n",
    "            )\n",
    "\n",
    "            extracted = extract_final_candidate(\n",
    "                gen_text\n",
    "            )\n",
    "            is_correct = grade_answer(\n",
    "                extracted, row[\"answer\"]\n",
    "            )\n",
    "            num_correct += int(is_correct)\n",
    "\n",
    "            record = {\n",
    "                \"index\": i,\n",
    "                \"problem\": row[\"problem\"],\n",
    "                \"gtruth_answer\": row[\"answer\"],\n",
    "                \"generated_text\": gen_text,\n",
    "                \"extracted\": extracted,\n",
    "                \"correct\": bool(is_correct),\n",
    "            }\n",
    "            f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "            progress_msg = eta_progress_message(\n",
    "                processed=i,\n",
    "                total=num_examples,\n",
    "                start_time=start_time,\n",
    "                show_eta=True,\n",
    "                label=\"MATH-500\",\n",
    "            )\n",
    "            print(progress_msg, end=\"\\r\", flush=True)\n",
    "            if verbose:\n",
    "                print(\n",
    "                    f\"\\n\\n{'='*50}\\n{progress_msg}\\n\"\n",
    "                    f\"{'='*50}\\nExtracted: {extracted}\\n\"\n",
    "                    f\"Expected:  {row['answer']}\\n\"\n",
    "                    f\"Correct so far: {num_correct}\\n{'-'*50}\"\n",
    "                )\n",
    "\n",
    "    seconds_elapsed = time.time() - start_time\n",
    "    acc = num_correct / num_examples if num_examples else 0.0\n",
    "    print(f\"\\nAccuracy: {acc*100:.1f}% ({num_correct}/{num_examples})\")\n",
    "    print(f\"Total time: {seconds_elapsed/60:.1f} min\")\n",
    "    print(f\"Logs written to: {out_path}\")\n",
    "    return num_correct, num_examples, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c760503-b57a-4947-b7bc-63620ebe2af9",
   "metadata": {},
   "source": [
    "- The improvements over the baseline in chapter 3 are shown below\n",
    "\n",
    "|    | Method                                       | Model     | Accuracy | Time       |\n",
    "|----|----------------------------------------------|-----------|----------|------------|\n",
    "| 1  | Baseline (chapter 3), greedy decoding        | Base      | 15.2%    | 10.1 min   |\n",
    "| 2  | Baseline (chapter 3), greedy decoding        | Reasoning | 48.2%    | 182.1 min  |\n",
    "| 3  | Chain-of-thought prompting (\"CoT\")           | Base      | 40.6%    | 84.5 min   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4971cdbf-2412-421e-b555-dbe2037b2c73",
   "metadata": {},
   "source": [
    "- For your convenience, you can run the [cot_prompting_math500.py](../02_math500-inference-scaling-scripts/cot_prompting_math500.py) script located in [../02_math500-inference-scaling-scripts](../02_math500-inference-scaling-scripts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc62f87-3d9d-47cd-9eed-6e15982e478c",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "## Exercise 4.2: Use temperature scaling and top-p filtering on MATH-500       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b6eea4-7b54-42d5-91f2-777a6b73c2af",
   "metadata": {},
   "source": [
    "- To be added"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6278a1-9c6c-45a9-9812-ce0c593bbf35",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "## Exercise 4.3: Use self-consistency sampling on MATH-500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa71a13-0f76-4a8b-aa82-d3ec85122674",
   "metadata": {},
   "source": [
    "- To be added"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c985e7ed-bca4-42b0-bf81-aa0eb0b0f3a7",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "## Exercise 4.4: Early stopping in self-consistency sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edec5192-e333-4972-8816-9774c4c33485",
   "metadata": {},
   "source": [
    "- To be added"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
